FROM nvidia/cuda:10.1-cudnn7-devel
# Set up locale to prevent bugs with encoding
ENV LANG=C.UTF-8 LC_ALL=C.UTF-8
ENV TZ=Europe/Paris
ENV DEBIAN_FRONTEND noninteractive

RUN ls /usr/local/cuda

RUN rm /etc/apt/sources.list.d/nvidia-ml.list
RUN rm /etc/apt/sources.list.d/cuda.list


RUN apt-get update && apt-get install -y \
	python3-opencv ca-certificates python3-dev git wget sudo ninja-build python3-venv python3-pip
RUN ln -sv /usr/bin/python3 /usr/bin/python
RUN  ln -s /usr/bin/pip3 /usr/bin/pip

WORKDIR /workspace

ENV PATH="/workspace/.local/bin:${PATH}"
#RUN wget --no-check-certificate  https://bootstrap.pypa.io/get-pip.py
#RUN python3 get-pip.py --proxy=$http_proxy   && \
#	rm get-pip.py
# install dependencies
# See https://pytorch.org/ for other options if you use a different version of CUDA
RUN pip install  tensorboard cmake   # cmake from apt-get is too old
RUN pip install  torch==1.8 torchvision==0.9 -f https://download.pytorch.org/whl/cu101/torch_stable.html

RUN git config --global  http.proxy $http_proxy
RUN git config --global  https.proxy $https_proxy
RUN pip install  'git+https://github.com/facebookresearch/fvcore'
# install detectron2
RUN git clone https://github.com/facebookresearch/detectron2 detectron2_repo
# set FORCE_CUDA because during `docker build` cuda is not accessible
ENV FORCE_CUDA="1"
# This will by default build detectron2 for all common cuda architectures and take a lot more time,
# because inside `docker build`, there is no way to tell which architecture will be used.
ARG TORCH_CUDA_ARCH_LIST="Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing"
ENV TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST}"

RUN pip install  -e detectron2_repo

# END OF DETECTRONS INSTALL
COPY . /workspace/iaflash
RUN pip --proxy=$http_proxy install  -r /workspace/iaflash/docker/torch-notebook/requirements.txt

RUN pip install  jupyter

RUN jupyter notebook --generate-config
RUN pip install  -e iaflash
CMD [ "python", "iaflash/iaflash/app/app.py" ]
